{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、model定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()  # 初始化父类nn.Module\n",
    "        \n",
    "        # 第一个卷积层: 输入3通道(RGB)，输出16特征图，卷积核大小5x5\n",
    "        # 输入为 32x32x3 的图像，经过卷积后变为 28x28x16\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        \n",
    "        # 第一个最大池化层: 窗口大小2x2，步长2\n",
    "        # 将特征图从 28x28x16 缩小为 14x14x16\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # 第二个卷积层: 输入16特征图，输出32特征图，卷积核大小5x5\n",
    "        # 输入为 14x14x16，经过卷积后变为 10x10x32\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        \n",
    "        # 第二个最大池化层: 窗口大小2x2，步长2\n",
    "        # 将特征图从 10x10x32 缩小为 5x5x32\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # 第一个全连接层: 将展平的特征图(5x5x32=800个神经元)连接到120个神经元\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        \n",
    "        # 第二个全连接层: 120个神经元连接到84个神经元\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # 输出层: 84个神经元连接到10个神经元(CIFAR10的10个类别)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入图像经过第一个卷积层，再通过ReLU激活函数，再经过最大池化\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        \n",
    "        # 第一层池化的输出经过第二个卷积层，再通过ReLU激活函数，再经过最大池化\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # 将卷积层输出的特征图展平为一维张量，-1表示自动计算批次大小\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "        \n",
    "        # 展平后的特征通过第一个全连接层和ReLU激活函数\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # 第一个全连接层的输出通过第二个全连接层和ReLU激活函数\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # 第二个全连接层的输出通过输出层(不使用激活函数，因为后续会使用交叉熵损失)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # 返回模型输出(logits)，用于计算损失和预测类别\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 定义预处理变换：将PIL图像转换为Tensor，并进行归一化处理\n",
    "# 归一化使像素值范围从[0,1]变为[-1,1]，有助于模型训练\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# 加载CIFAR10训练数据集，共50000张图像\n",
    "# root指定数据集存储位置，transform应用上述预处理\n",
    "# download=True表示如果本地没有则从网络下载\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=True, download=True, transform=transform)\n",
    "\n",
    "# 创建训练数据加载器，以便批量读取数据\n",
    "# batch_size=128: 每次读取128张图片\n",
    "# shuffle=True: 随机打乱数据，防止模型学习到数据顺序\n",
    "# num_workers=0: 不使用多进程加载数据\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "# 加载CIFAR10测试数据集，共10000张图像\n",
    "testset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=False, download=True, transform=transform)\n",
    "\n",
    "# 创建测试数据加载器\n",
    "# batch_size=10000: 一次性加载全部测试集，方便评估\n",
    "# shuffle=False: 不打乱测试数据顺序\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10000, shuffle=False, num_workers=0)\n",
    "\n",
    "# 获取测试数据集的迭代器，并获取一批测试数据\n",
    "test_data_iter = iter(testloader)\n",
    "test_images, test_labels = next(test_data_iter)\n",
    "\n",
    "# CIFAR10数据集的10个类别名称\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 定义图像显示函数\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # 反归一化，将像素值从[-1,1]恢复到[0,1]\n",
    "    npimg = img.numpy()     # 将PyTorch Tensor转换为NumPy数组\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # 调整维度顺序以符合matplotlib要求\n",
    "    plt.show()\n",
    "\n",
    "# 获取测试集的迭代器\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 显示一批测试图像\n",
    "imshow(torchvision.utils.make_grid(test_images))  # make_grid将多张图片拼成一个网格图像\n",
    "\n",
    "# 打印前4个图像的标签\n",
    "print(' '.join(f'{classes[test_labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):  # 训练5个轮次\n",
    "    running_loss = 0.0  # 用于累计一定批次内的损失值\n",
    "    for i, data in enumerate(trainloader, start=0):  # 遍历训练数据集，enumerate同时返回数据和数据索引\n",
    "        # 获取输入数据和标签\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # 梯度清零，防止梯度累积\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播：将输入数据传入模型得到输出\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # 计算损失：比较模型输出与真实标签之间的差异\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # 反向传播：计算损失对各参数的梯度\n",
    "        loss.backward()\n",
    "        \n",
    "        # 参数更新：根据梯度和学习率更新模型参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 累加当前批次的损失值\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 每500批次评估一次模型性能并打印训练信息\n",
    "        if i % 300 == 299:\n",
    "            # 使用torch.no_grad()避免在评估时计算梯度，节省内存\n",
    "            with torch.no_grad():\n",
    "                # 对测试图像进行前向传播\n",
    "                outputs = net(test_images)\n",
    "                # 获取每个样本的预测类别（概率最高的类别索引）\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                # 计算准确率：预测正确的样本数 / 总样本数\n",
    "                accuracy = torch.eq(predict_y, test_labels).sum().item() / test_labels.size(0)\n",
    "                # 打印当前轮次、批次、平均损失和测试准确率\n",
    "                print(f'epoch: {epoch}, step: {i} loss: {running_loss / 300:.3f} test accuracy: {accuracy:.3f}')\n",
    "                # 重置累计损失值\n",
    "                running_loss = 0.0\n",
    "\n",
    "# 训练结束提示\n",
    "print('Finished Training')\n",
    "# 保存训练好的模型参数到文件\n",
    "torch.save(net.state_dict(), './lenet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
